{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3D_res_attn_Unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmD9SLQpmNJF",
        "outputId": "b229d162-0469-458b-dea9-844285888231"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 16 12:47:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9lUYIN8M0Z6",
        "outputId": "fe4cd177-67f8-43d0-cf54-ead42700eb73"
      },
      "source": [
        "!apt install libcudnn8 --allow-change-held-packages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8 libcudnn8-dev\n",
            "2 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,037 MB of archives.\n",
            "After this operation, 340 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8-dev 8.2.0.53-1+cuda11.3 [582 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.2.0.53-1+cuda11.3 [454 MB]\n",
            "Fetched 1,037 MB in 38s (27.0 MB/s)\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8-dev_8.2.0.53-1+cuda11.3_amd64.deb ...\n",
            "Unpacking libcudnn8-dev (8.2.0.53-1+cuda11.3) over (8.0.4.30-1+cuda11.0) ...\n",
            "Preparing to unpack .../libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.2.0.53-1+cuda11.3) over (8.0.4.30-1+cuda11.0) ...\n",
            "Setting up libcudnn8 (8.2.0.53-1+cuda11.3) ...\n",
            "Setting up libcudnn8-dev (8.2.0.53-1+cuda11.3) ...\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/include/x86_64-linux-gnu/cudnn_v7.h because link group libcudnn is broken\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in manual mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZI13ut7nBZF",
        "outputId": "9d13d807-80e6-4a21-aa34-b0b711e1b7f8"
      },
      "source": [
        "%pip install -q tensorflow-addons[tensorflow]\n",
        "%pip install -q simpleitk\n",
        "# %pip install -q colab_ssh\n",
        "%pip install -q wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 686kB 14.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.4MB 109kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 15.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 57.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 55.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeRBZZsrxy7G",
        "outputId": "87211e1d-4fef-4426-a497-854aa6d9ea5c"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1jYb-dKqywLm5bQ5esP6YSV5xuBzqBPqm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jYb-dKqywLm5bQ5esP6YSV5xuBzqBPqm\n",
            "To: /content/BRATS_Dataset.tar.gz\n",
            "2.76GB [00:39, 70.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCwAJtyIx0oX"
      },
      "source": [
        "!apt -qq install pigz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBS9P9pVyL0p"
      },
      "source": [
        "!pigz -dc BRATS_Dataset.tar.gz | tar xf -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwMjK_O6yL-5"
      },
      "source": [
        "!rm BRATS_Dataset.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bu-os4Kqoiq"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf 3D_res_attn_Unet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5UZTWx-mb7Y"
      },
      "source": [
        "!git clone https://github.com/ShivamShrirao/3D_res_attn_Unet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDsMVBQUEX_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575a2be8-8035-4fd6-8d91-10d1c822cd7a"
      },
      "source": [
        "%cd 3D_res_attn_Unet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/3D_res_attn_Unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYq1D1nrmMfW"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxV8loizyQk5"
      },
      "source": [
        "import SimpleITK as sitk"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyvK3bkmmRF5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "from time import time\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke4itk7LVPXP"
      },
      "source": [
        "# Set the random seeds\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8wLJQSNmV8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae5d04f-d9b5-4792-a12e-37e782a3ec07"
      },
      "source": [
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_policy(policy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-16GB, compute capability 7.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH9zA80Lyblg"
      },
      "source": [
        "def get_data_paths(dataset_path):\n",
        "    t1 = glob.glob(dataset_path+'/*GG/*/*t1.nii.gz')\n",
        "    t2 = glob.glob(dataset_path+'/*GG/*/*t2.nii.gz')\n",
        "    t1ce = glob.glob(dataset_path+'/*GG/*/*t1ce.nii.gz')\n",
        "    flair = glob.glob(dataset_path+'/*GG/*/*flair.nii.gz')\n",
        "    seg = glob.glob(dataset_path+'/*GG/*/*seg.nii.gz')\n",
        "    return list(zip(t1, t2, t1ce, flair, seg))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoB8nSTVyfUX"
      },
      "source": [
        "train_paths = get_data_paths('../BRATS_Dataset/brats_dataset/')\n",
        "val_paths = get_data_paths('../BRATS_Dataset/brats_test_dataset/')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2BFkvT4yfRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107e96f7-31bc-4d97-ead5-07c7beceba34"
      },
      "source": [
        "len(train_paths), len(val_paths)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(285, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-GTEwiqy1E_"
      },
      "source": [
        "from model.preprocess_brats import *"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNGVcTA5fS51"
      },
      "source": [
        "mean = tf.constant([-0.7050362 , -0.76629126, -0.8043347 , -0.77532315], shape=(1, 4, 1, 1, 1))\n",
        "std  = tf.constant([0.40932664, 0.33403134, 0.26365048, 0.31701902], shape=(1, 4, 1, 1, 1))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLUheTvAyfNE"
      },
      "source": [
        "# mean = 0\n",
        "# std = 0\n",
        "# for i, (img,lbl) in tqdm(enumerate(train_ds)):\n",
        "#     if i == 200//BATCH_SIZE:\n",
        "#         break\n",
        "#     mean+= tf.reduce_mean(img, axis=[0,2,3,4])\n",
        "#     std += tf.math.reduce_std(img, axis=[0,2,3,4])\n",
        "# mean = tf.reshape(mean/i, (1, 4, 1, 1, 1))\n",
        "# std = tf.reshape(std/i, (1, 4, 1, 1, 1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gELRSfJLyfKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2029541-fe5f-4f14-80a0-0bef5a336db5"
      },
      "source": [
        "depth = 128 # 155\n",
        "height = 192 # 240\n",
        "width = 160 # 240\n",
        "(155-depth, 240-height, 240-width)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 48, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA8i-idEyfGn"
      },
      "source": [
        "def random_crop3D(imgs, lbls, train=True):          # Crops image to size (128, 192, 160)\n",
        "    d_cr, h_cr, w_cr = 13, 24, 40\n",
        "    if train:\n",
        "        if tf.random.uniform([], 0, 1, dtype=tf.float32) <= 0.8:\n",
        "            d_cr = tf.random.uniform([], 0, 27, dtype=tf.int32)\n",
        "            h_cr = tf.random.uniform([], 0, 48, dtype=tf.int32)\n",
        "            w_cr = tf.random.uniform([], 0, 80, dtype=tf.int32)\n",
        "    imgs = imgs[:, :, d_cr:d_cr+depth, h_cr:h_cr+height, w_cr:w_cr+width]\n",
        "    lbls = lbls[:, :, d_cr:d_cr+depth, h_cr:h_cr+height, w_cr:w_cr+width]\n",
        "    return imgs, lbls"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNBpYsiZCMLv"
      },
      "source": [
        "def final_augmentation(imgs, lbls, train=True):       # input imgs[B, 4, 155, 240, 240], output[B, 4, 128, 192, 160]\n",
        "    imgs, lbls = random_crop3D(imgs, lbls, train)\n",
        "    if train:\n",
        "        if tf.random.uniform([], 0, 1, dtype=tf.float32) <= 0.8:\n",
        "            imgs = tf.image.random_brightness(imgs, 0.2)      # source code checked, it's fine for 3D\n",
        "    # imgs = tf.image.per_image_standardization(imgs)   # source code checked, it's fine for 3D\n",
        "    imgs = (imgs - mean) / std\n",
        "    return imgs, lbls"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jYQgwzeye7w"
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CRpmKSryeMY"
      },
      "source": [
        "def get_tfds(data_paths, train=False):\n",
        "    # 53.3373920917511 s\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data_paths)\n",
        "    if train:\n",
        "        dataset = dataset.shuffle(len(data_paths))\n",
        "    dataset = dataset.map(load_paths_wrapper, num_parallel_calls=AUTOTUNE)\n",
        "    # if train:\n",
        "    #     dataset = dataset.map(random_rotate3D, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    if train:\n",
        "        dataset = dataset.map(random_flip3D, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.map(lambda x,y: final_augmentation(x,y,train), num_parallel_calls=AUTOTUNE)      # remove for test,val\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLVvTfMPzSgG"
      },
      "source": [
        "train_ds = get_tfds(train_paths, train=True)\n",
        "val_ds = get_tfds(val_paths)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_u6nfUhzT9C"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39ZKOyeDzT6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02eb4443-5f7a-47bf-cfd5-fb4aa77e0ef5"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivamshrirao\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUud1K2iloXZ"
      },
      "source": [
        "config_defaults = {\n",
        "    'activation'            : 'elu', # swish, elu\n",
        "    'batch_size'            : BATCH_SIZE,\n",
        "    'block_type'            : 'AttnBottleneckBlock',\n",
        "    'clr_step_size'         : 100,      # start from between with big step in one cycle\n",
        "    'clr_offset_ep'         : 10,        # also warmup steps\n",
        "    'downsample_method'     : 'pool',\n",
        "    'dp_rate'               : 0.24,\n",
        "    'dropout_type'          : 'Spatial',\n",
        "    'frac_dv'               : 0.25,\n",
        "    'groups'                : 'max',                 # imp. = 48\n",
        "    'loss_function'         : 'FocalTversky',\n",
        "    'max_lr'                : 8e-4,\n",
        "    'min_lr'                : 1e-6,\n",
        "    'nheads'                : 8,\n",
        "    'norm'                  : 'gn',\n",
        "    'optimizer'             : 'adamw',\n",
        "    'weight_decay'          : 3e-5,     # max weight decay\n",
        "    'z_notes'               : ['kernel size 5 input','removed random rotation']\n",
        "}\n",
        "CONFIG = config_defaults"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTWSlkaTUVIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0dde6f6b-ff51-4456-d7c4-503ae04210a0"
      },
      "source": [
        "run = wandb.init(id='n89505wh', project=\"3D_res_attn_Unet\", resume='must')\n",
        "CONFIG = run.config"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.32<br/>\n",
              "                Resuming run <strong style=\"color:#cdcd00\">twilight-voice-58</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/shivamshrirao/3D_res_attn_Unet\" target=\"_blank\">https://wandb.ai/shivamshrirao/3D_res_attn_Unet</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/shivamshrirao/3D_res_attn_Unet/runs/n89505wh\" target=\"_blank\">https://wandb.ai/shivamshrirao/3D_res_attn_Unet/runs/n89505wh</a><br/>\n",
              "                Run data is saved locally in <code>/content/3D_res_attn_Unet/wandb/run-20210616_143909-n89505wh</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjaGe7P4z1qV"
      },
      "source": [
        "run = wandb.init(project=\"3D_res_attn_Unet\", entity=\"shivamshrirao\", config=config_defaults)\n",
        "CONFIG = wandb.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PNd1IfZ7D-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a03998-6beb-4a6c-f0f0-73fc0a362743"
      },
      "source": [
        "mean.numpy().ravel(), std.numpy().ravel()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.7050362 , -0.76629126, -0.8043347 , -0.77532315], dtype=float32),\n",
              " array([0.40932664, 0.33403134, 0.26365048, 0.31701902], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muugExNpz1lY"
      },
      "source": [
        "tf.keras.backend.set_image_data_format('channels_first')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRbHoACDz8_D"
      },
      "source": [
        "## attention shortcuts to be used.\n",
        "## try attention on the unet shortcuts\n",
        "## try Global Context Block\n",
        "## try input image pyramid and deep supervised output layers (output from intermediate layers (fuse with conv-sigmoid like U^2net ??))\n",
        "## TRY PIXELSHUFFLE\n",
        "## Try SPARSE CONV NET https://github.com/facebookresearch/SparseConvNet"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO3HwVYoEpFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3984f5b9-4322-489b-d405-e4db73f46cca"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRY6Np0vmy6h"
      },
      "source": [
        "from model.conv_blocks import *"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uar0LFgp0n1-"
      },
      "source": [
        "from model.losses import *\n",
        "from model.utils import *"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N09vgsSSh4Ch"
      },
      "source": [
        "steps_per_epoch = int(np.ceil(len(train_paths)/BATCH_SIZE))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWXn8he2nt5W"
      },
      "source": [
        "def enc_dec(x, block, frac_dv, stack_args):     # x(64,64,96,80)\n",
        "    x1 = down_stack(x ,  64, nblocks=2, block=block, strides=2, **stack_args)     # (256,32,48,40)\n",
        "    x2 = down_stack(x1, 128, nblocks=2, block=block, strides=2, **stack_args)     # (512,16,24,20)\n",
        "    x3 = down_stack(x2, 256, nblocks=2, block=block, strides=2, frac_dv=frac_dv, **stack_args) # (1024, 8,12,10)\n",
        "    x4 = down_stack(x3, 256, nblocks=3, block=block, strides=2, frac_dv=frac_dv, **stack_args) # (1024, 4, 6, 5)\n",
        "\n",
        "    y = up_stack(x4,x3, 128, nblocks=3, block=block, strides=2, frac_dv=frac_dv, **stack_args) # (1024+1024->512,8,12,10)\n",
        "    y = up_stack(y, x2,  64, nblocks=2, block=block, strides=2, **stack_args)     # (512+512->256,16,24,20)\n",
        "    y = up_stack(y, x1,  32, nblocks=2, block=block, strides=2, **stack_args)     # (256+256->128,32,48,40)\n",
        "    y = up_stack(y, x ,  16, nblocks=1, block=block, strides=2, **stack_args)     # (128+ 64-> 64,64,96,80)\n",
        "    return y\n",
        "\n",
        "\n",
        "def build_network(cfg, block, input_shape=(4,128,192,160), classes=4):\n",
        "    stack_args = {'activation': cfg['activation'], 'groups': cfg['groups'], 'norm': cfg['norm'], 'dp_rate': cfg['dp_rate'],\n",
        "                  'dropout_type': cfg['dropout_type'], 'downsample_method': cfg['downsample_method']}\n",
        "\n",
        "    inp = layers.Input(shape=input_shape)                           # ( 4,128,192,160)\n",
        "    x = inp\n",
        "    x = ConvNorm(32, kernel_size=5, strides=2, activation=cfg['activation'], norm=cfg['norm'])(x)   # (32,64,96,80)\n",
        "    x = ConvNorm(64, kernel_size=3, do_norm_act=False)(x)                               # (64, 64, 96, 80)\n",
        "\n",
        "    x = enc_dec(x, block, cfg['frac_dv'], stack_args)                                   # (64, 64, 96, 80)\n",
        "\n",
        "    x = NormAct(activation=cfg['activation'], norm=cfg['norm'])(x)\n",
        "    x = layers.UpSampling3D(data_format=\"channels_first\")(x)                            # (64,128,192,160)\n",
        "    x = ConvNorm(16, kernel_size=3, activation=cfg['activation'], norm=cfg['norm'])(x)  # (16,128,192,160)\n",
        "    x = ConvNorm(classes, kernel_size=3, do_norm_act=False)(x)                          #(3,128,192,160)\n",
        "    x = layers.Softmax(axis=1)(x)         # softmax cause each pixel has unique class, no overlap with other classes, verified.\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=x)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3He9IJQqzHq"
      },
      "source": [
        "block = AttnBottleneckBlock\n",
        "CONFIG['block_type'] = block.__name__\n",
        "model = build_network(CONFIG, block, input_shape=(4,depth,height,width), classes=4)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alHQI9fntI0U"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjkU03lnbji3"
      },
      "source": [
        "model_plot = tf.keras.utils.plot_model(model, '/content/model.png', show_shapes=True, dpi=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83ItIV7aZHed"
      },
      "source": [
        "wandb.log({\"model\": wandb.Image(\"/content/model.png\")})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXx318sknylB"
      },
      "source": [
        "from tensorflow.python.client import session\n",
        "from tensorflow.python.summary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gylV6eyKXj_c"
      },
      "source": [
        "log_dir = run.dir+\"/trace_log\"\n",
        "!rm -rf $log_dir\n",
        "\n",
        "@tf.function\n",
        "def trace(x):\n",
        "    return model(x)\n",
        "\n",
        "data = tf.random.normal((2,) + model.input_shape[1:])\n",
        "data = tf.constant(data)\n",
        "\n",
        "imported_g = trace.get_concrete_function(data).graph\n",
        "\n",
        "# Export the graph\n",
        "with session.Session(graph=imported_g) as sess:\n",
        "    pb_visual_writer = summary.FileWriter(log_dir)\n",
        "    pb_visual_writer.add_graph(sess.graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0GzUyfRXt_G"
      },
      "source": [
        "%tensorboard --logdir $log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDQCKTmBjlOt"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(6006)\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tPMPpMFZ4eq"
      },
      "source": [
        "clr_offset = CONFIG[\"clr_offset_ep\"] * steps_per_epoch\n",
        "clr_step   = CONFIG['clr_step_size'] * steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46U9U1PNW9AC"
      },
      "source": [
        "clr = WarmupExponentialDecay(\n",
        "                    initial_learning_rate=CONFIG['max_lr'],\n",
        "                    decay_steps=clr_step,\n",
        "                    decay_rate=CONFIG['min_lr']/CONFIG['max_lr'],\n",
        "                    warmup_steps=clr_offset)\n",
        "\n",
        "wdc = WarmupExponentialDecay(\n",
        "                    initial_learning_rate=CONFIG['weight_decay'],\n",
        "                    decay_steps=clr_step,\n",
        "                    decay_rate=CONFIG['min_lr']/CONFIG['max_lr'],\n",
        "                    warmup_steps=clr_offset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lX3j_he0nxj"
      },
      "source": [
        "# clr = CustomCLR(\n",
        "#         offset=clr_offset,\n",
        "#         initial_learning_rate=CONFIG[\"min_lr\"],\n",
        "#         maximal_learning_rate=CONFIG[\"max_lr\"],\n",
        "#         step_size=clr_step,\n",
        "#         scale_mode=\"cycle\")\n",
        "\n",
        "# wdc = CustomCLR(\n",
        "#         offset=clr_offset,\n",
        "#         initial_learning_rate=CONFIG[\"weight_decay\"]*CONFIG[\"min_lr\"]/CONFIG[\"max_lr\"],\n",
        "#         maximal_learning_rate=CONFIG[\"weight_decay\"],\n",
        "#         step_size=clr_step,\n",
        "#         scale_mode=\"cycle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqk_6JVV03Ue"
      },
      "source": [
        "if CONFIG[\"optimizer\"] == 'adamw':\n",
        "    opt = tfa.optimizers.AdamW(learning_rate=clr, weight_decay=wdc)\n",
        "elif CONFIG[\"optimizer\"] == 'adam':            # or just make weight_decay=0\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=clr)\n",
        "opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVv7YFEA03SE"
      },
      "source": [
        "if CONFIG[\"loss_function\"] == 'FocalTversky':\n",
        "    loss_function = FocalTversky()\n",
        "elif CONFIG[\"loss_function\"] == 'cce':\n",
        "    loss_function = cce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbb5bvp_03Pc"
      },
      "source": [
        "model.compile(optimizer=opt, loss=loss_function, metrics=[dsc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSWPV3PxP0Gd"
      },
      "source": [
        "model.save(wandb.run.dir+\"/model-best.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItS5R3MwOzlZ"
      },
      "source": [
        "wandb.save(\"*.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGDA2XLen0do"
      },
      "source": [
        "# model = tf.keras.models.load_model(wandb.restore(\"model-best.h5\").name, custom_objects={'ConvNorm': ConvNorm,\n",
        "#                                                                                         'NormAct': NormAct,\n",
        "#                                                                                         'AttnBottleneckBlock': AttnBottleneckBlock,\n",
        "#                                                                                         'BasicBlock': BasicBlock,\n",
        "#                                                                                         'InvertedResBlock': InvertedResBlock,\n",
        "#                                                                                         'SqueezeExcite': SqueezeExcite,\n",
        "#                                                                                         'MHSA3D': MHSA3D,\n",
        "#                                                                                         'AbsPosEmb': AbsPosEmb,\n",
        "#                                                                                         'dsc': dsc,\n",
        "#                                                                                         'FocalTversky': FocalTversky,\n",
        "#                                                                                         'CustomCLR': CustomCLR,\n",
        "#                                                                                         'WarmupExponentialDecay': WarmupExponentialDecay,\n",
        "#                                                                                         })\n",
        "# model.compile(optimizer=model.optimizer, loss=model.loss, metrics=[dsc])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dD2Nbrh0-5O"
      },
      "source": [
        "wandb_cb = WandbCallback(monitor='dsc', mode='max')\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        img, lbl = next(iter(val_ds))\n",
        "        pred = self.model(img)\n",
        "        i = epoch % BATCH_SIZE\n",
        "        img = img[i,1].numpy()\n",
        "        mn = img.min()\n",
        "        mx = img.max()\n",
        "        img = (img - mn)/(mx - mn) * 255\n",
        "        lbl = lbl[i,1:].numpy()*255\n",
        "        pred = pred[i,1:].numpy()*255\n",
        "        get_gif(img, lbl, pred, \"out.gif\")\n",
        "        wandb.log({\"Outputs\": wandb.Image(\"out.gif\"),\n",
        "                   \"lr\": self.model.optimizer.inner_optimizer._decayed_lr('float32').numpy()})\n",
        "        self.model.save(wandb.run.dir+\"/model-best.h5\")\n",
        "        wandb.save(\"*.h5\")                      # For forcing sync\n",
        "        gc.collect()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqqKSGy8S_zC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27a074f-3f4b-4ebc-a291-61f5afaabe16"
      },
      "source": [
        "initial_epoch = int(tf.round(model.optimizer.iterations/steps_per_epoch))\n",
        "initial_epoch"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt9JdTqugB1_",
        "outputId": "b1762ed6-60fe-4615-f48a-e506d0b9aee4"
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch=np.ceil(len(train_paths)/BATCH_SIZE),\n",
        "                    validation_data=val_ds,\n",
        "                    validation_steps=np.ceil(len(val_paths)//BATCH_SIZE),\n",
        "                    initial_epoch=initial_epoch,\n",
        "                    workers=3,\n",
        "                    callbacks=[CustomCallback(), wandb_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 60/100\n",
            "143/143 [==============================] - 263s 2s/step - loss: 0.9466 - dsc: 0.7578 - val_loss: 0.6932 - val_dsc: 0.8332\n",
            "Epoch 61/100\n",
            " 70/143 [=============>................] - ETA: 1:40 - loss: 0.9100 - dsc: 0.7693"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEwOLSTe1lRg"
      },
      "source": [
        "model.evaluate(val_ds, steps=np.ceil(len(val_paths)//BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttJA6gGL1pv7"
      },
      "source": [
        "scores = []\n",
        "for i, (a,b) in tqdm(enumerate(train_ds)):\n",
        "    if i==steps_per_epoch:\n",
        "        break\n",
        "    o = model(a)\n",
        "    o = tf.cast(o, tf.float32)\n",
        "    scores.append(dsc(b,o))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1UO7i_1ppa"
      },
      "source": [
        "np.mean(scores, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qi8enp1maS"
      },
      "source": [
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0uCOgvkQJmi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}